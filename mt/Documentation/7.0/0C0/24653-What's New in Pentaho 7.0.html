<content type="text/html" title="What's New in Pentaho 7.0">
  <body>
    <div class="pentaho-overview-hidden">
      <div id="section_1" class="mt-page-section"><span id="Overview"></span> 
        <h2 class="editable">Overview</h2>
      </div>
    </div>
    <p>Pentaho 7.0&nbsp;delivers a wide range of new capabilities, from enhanced big data security features to time-saving advanced data exploration functionality. The highlight of the release is the ability to visually explore your data anywhere in the
      pipeline while working in Pentaho Data Integration (PDI). Pentaho 7.0 also continues to build on the investments made in big data security, a unified Pentaho Server, metadata injection, and many other improvements to the enterprise platform.&nbsp;</p>
    <div id="section_2" class="mt-page-section"><span id="Inspect_Your_Data.2C_Anywhere_in_the_Pipeline"></span> 
      <h2 style="visibility: visible;" class="editable">I<span class="mt-bgcolor-ffffff">nspect Your Data</span> 
        <ins cite="mailto:Greg%20Stauffeneker" datetime="2016-10-27T19:14"><span class="mt-bgcolor-ffffff">,&nbsp;</span> </ins>
        <ins cite="mailto:Greg%20Stauffeneker" datetime="2016-10-27T19:13"><span class="mt-bgcolor-ffffff">A</span> </ins><span class="mt-bgcolor-ffffff">nywhere in the Pipeline&nbsp;</span> </h2>
      <p>You can now spot check your transformation data in-flight using PDI, without having to switch in and out of tools. By previewing the data and using an array of available visualizations, you can test, refine and prep the data set for specific data
        models before publishing it as a source for analytical reports. Visualizing data in-flight and during the data-prep process is unique to Pentaho. Learn more about in&nbsp;
        <a title="Inspecting Your Data" rel="internal" href="http://help.pentaho.com/Documentation/7.0/0L0/0Y0/Inspecting_Your_Data">Inspecting Your Data</a> .&nbsp;</p>
    </div>
    <div id="section_3" class="mt-page-section"><span id="Improved_Big_Data_Security"></span> 
      <h2 class="editable">Improved Big Data Security</h2>
      <p>The&nbsp;new Pentaho Server now promotes a more secure big data integration by supporting Kerberos impersonation. This allows multiple PDI users to access Kerberos-enabledClouderaHadoop clusters as multiple authenticated Hadoop users. The Pentaho
        server also works with Cloudera Sentry to control access to specific data within Hadoop &ndash; based on a user&rsquo;s role in the organization &ndash; to enforce enterprise data authorization,Kerberos authentication and secure impersonation
        on Hadoop clusters. Learn more about&nbsp;
        <a title="Setting Up User Security" rel="internal" href="http://help.pentaho.com/Documentation/7.0/0P0/Setting_Up_User_Security">Setting Up User Security</a> .</p>
    </div>
    <div id="section_4" class="mt-page-section"><span id="Easier_Installation_and_Configuration_with_the_Single_Pentaho_Server"></span> 
      <h2 class="editable"><span class="mt-bgcolor-ffffff">Easier Installation</span> 
        <ins cite="mailto:Greg%20Stauffeneker" datetime="2016-10-27T18:55"><span class="mt-bgcolor-ffffff"> and Configuration</span> </ins><span class="mt-bgcolor-ffffff"> with the Single </span> <span class="mt-bgcolor-ffffff">Pentaho</span> <span class="mt-bgcolor-ffffff"> Server&nbsp;</span> </h2>
      <p>Pentaho&rsquo;s Business Analytics (BA) Server and Data Integration (DI) Server have been merged and renamed the Pentaho Server.&nbsp;Since the BA and DI components are now integrated, the complexity of installing and configuring two separate servers
        is eliminated. Learn more about&nbsp;
        <a title="Installation" rel="internal" href="http://help.pentaho.com/Documentation/7.0/0F0">Installation</a> &nbsp;and&nbsp;
        <a title="Configuration" rel="internal" href="http://help.pentaho.com/Documentation/7.0/0H0">Configuration</a> &nbsp;of the&nbsp;Pentaho Server.</p>
    </div>
    <div id="section_5" class="mt-page-section"><span id="Enhanced_Spark_Support"></span> 
      <h2 class="editable">Enhanced Spark Support</h2>
      <p>The Spark Submit job entry now supports Spark code written in Scala and Python. Learn more about the&nbsp;
        <a title="Spark Submit" rel="internal" href="http://help.pentaho.com/Documentation/7.0/0L0/0Y0/0L0/Spark_Submit">Spark Submit</a> &nbsp;job entry.&nbsp;The Spark Submit job entry now supports Kerberos authentication on Cloudera (CDH) distributions of Hadoop clusters. Learn more about&nbsp;
        <a title="Using Kerberos Authentication with Spark Submit" rel="internal"
        href="http://help.pentaho.com/Documentation/7.0/0P0/Setting_Up_Big_Data_Security/Using_Kerberos_Authentication_with_Spark_Submit">Using Kerberos Authentication with Spark Submit</a> .&nbsp;Spark SQL databases can now be used as data sources when working with Hortonworks (HDP) distributions of Hadoop clusters. Learn more about&nbsp;
        <a title="Components Reference" rel="internal"
        href="http://help.pentaho.com/Documentation/7.0/0D0/160/000#Big_Data_Sources">Spark SQL data source support</a> .</p>
    </div>
    <div id="section_6" class="mt-page-section"><span id="Expanded_Metadata_Injection_Support"></span> 
      <h2 class="editable">
        <ins cite="mailto:Greg%20Stauffeneker" datetime="2016-10-27T19:11"><span class="mt-bgcolor-ffffff">Expanded&nbsp;</span> </ins><span class="mt-bgcolor-ffffff">Metadata</span> <span class="mt-bgcolor-ffffff"> Injection Support&nbsp;</span> </h2>
      <p>You can now inject metadata into any field of the following Pentaho Data Integration steps:</p>
      <ul>
        <li>Big Data - Avro Input, Cassandra Input, Cassandra Output, CouchDB Input, Hadoop File Input, Hadoop File Output, HBase Input, HBase Output, HBase Row <span class="mt-bgcolor-ffffff">Decoder, </span> <span class="mt-bgcolor-ffffff">MapReduce</span> 
          <span
          class="mt-bgcolor-ffffff"> Input, </span> <span class="mt-bgcolor-ffffff">MapReduce</span> <span class="mt-bgcolor-ffffff"> Output, </span> <span class="mt-bgcolor-ffffff">MongoDB</span> <span class="mt-bgcolor-ffffff"> Input, </span> <span class="mt-bgcolor-ffffff">MongoDB</span> 
            <span
            class="mt-bgcolor-ffffff"> Output</span>,&nbsp;</li>
        <ins cite="mailto:Greg%20Stauffeneker" datetime="2016-10-27T19:10"><span class="mt-bgcolor-ffffff">Splunk</span> <span class="mt-bgcolor-ffffff"> Input, </span> <span class="mt-bgcolor-ffffff">Splunk</span> <span class="mt-bgcolor-ffffff"> Output</span> </ins>
        <li>Bulk Loading - Greenplum Load, MySQL Bulk Loader, Oracle Bulk Loader, Vertical Bulk Loader</li>
        <li>Data Warehouse - Combination Lookup / Update</li>
        <li>Flow - Annotate Stream, Append Streams, ETL Metadata Injection, Filter Rows, Shared Dimension, Switch / Case</li>
        <li>Input - Get Table Names, JSON Input</li>
        <li>Job - Get Variables</li>
        <li>Joins - Join Rows (Cartesian product), Merge Join, Merge Rows, Multiway Merge Join, Sorted Merge, XML Join</li>
        <li>Output - Insert / Update, Synchronize After Merge, Update</li>
        <li>Statistics - Memory Group By</li>
        <li>Transform - Add XML, Replace in String</li>
        <li>Utility - If Field Value is Null, Null If</li>
        <li>Validation - Data Validator</li>
      </ul>
      <p>Learn more about&nbsp;the&nbsp;
        <a title="ETL Metadata Injection" rel="internal" href="http://help.pentaho.com/Documentation/7.0/0L0/0Y0/0K0/ETL_Metadata_Injection"> <span class="mt-color-#005DA6">ETL Metadata Injection</span>  </a> &nbsp;step.</p>
      <p>We have added&nbsp;documentation on how to add metadata injection support to steps you have created as plugins. For more information, see&nbsp;
        <a title="Create Step Plugins" rel="internal" href="http://help.pentaho.com/Documentation/7.0/0R0/0V0/010/000#Add_Metadata_Injection_Support_to_Your_Step">Add Metadata Injection Support to Your Step</a> .</p>
    </div>
    <div id="section_7" class="mt-page-section"><span id="Improved_Repository_Management"></span> 
      <h2 class="editable">Improved Repository Management</h2>
      <p>Now with just a single click from the PDI client, you can create and manage your repositories with easy to follow steps. Learn more about&nbsp;
        <a title="Work with Repositories" rel="internal" href="http://help.pentaho.com/Documentation/7.0/0L0/0Y0/040"> <span class="mt-color-#005DA6">Work with Repositories</span>  </a> .</p>
    </div>
    <div id="section_8" class="mt-page-section"><span id="Agile_BI_Plugin"></span> 
      <h2 class="editable">Agile BI Plugin</h2>
      <p>Agile BI will no longer ship in a Pentaho distribution. Agile BI is still available as a Marketplace plugin.</p>
    </div>
  </body>
  <body target="toc">
    <ol>
      <li> <a href="#Overview" rel="internal">Overview</a>  </li>
      <li> <a href="#Inspect_Your_Data.2C_Anywhere_in_the_Pipeline" rel="internal">Inspect Your Data,&nbsp;Anywhere in the Pipeline&nbsp;</a>  </li>
      <li> <a href="#Improved_Big_Data_Security" rel="internal">Improved Big Data Security</a>  </li>
      <li> <a href="#Easier_Installation_and_Configuration_with_the_Single_Pentaho_Server" rel="internal">Easier Installation and Configuration with the Single Pentaho Server&nbsp;</a>  </li>
      <li> <a href="#Enhanced_Spark_Support" rel="internal">Enhanced Spark Support</a>  </li>
      <li> <a href="#Expanded_Metadata_Injection_Support" rel="internal">Expanded&nbsp;Metadata Injection Support&nbsp;</a>  </li>
      <li> <a href="#Improved_Repository_Management" rel="internal">Improved Repository Management</a>  </li>
      <li> <a href="#Agile_BI_Plugin" rel="internal">Agile BI Plugin</a>  </li>
    </ol>
  </body>
</content>